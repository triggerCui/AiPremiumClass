import csv
import sentencepiece as spm
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# 准备训练SentencePiece模型的数据
text_for_spm = []
with open('DMSC.csv', 'r') as file:
    reader = csv.DictReader(file)
    for row in reader:
        vote = int(row['Star'])
        if vote in [1, 2, 4, 5]:
            text_for_spm.append(row['Comment'])

# 将数据保存到临时文件
with open('spm_train_data.txt', 'w', encoding='utf-8') as f:
    for line in text_for_spm:
        f.write(line + '\n')

# 训练SentencePiece模型
spm.SentencePieceTrainer.train(input='spm_train_data.txt', model_prefix='spm_model', vocab_size=8000)

# 加载训练好的SentencePiece模型
sp = spm.SentencePieceProcessor()
sp.load('spm_model.model')

ds_comments = []
# 加载数据并进行分词
with open('DMSC.csv', 'r') as file:
    reader = csv.DictReader(file)
    for row in reader:
        vote = int(row['Star'])
        if vote in [1, 2, 4, 5]:
            label = 1 if vote in [1, 2] else 0
            # 使用SentencePiece进行分词
            words = sp.encode_as_pieces(row['Comment'])
            ds_comments.append((' '.join(words), label))

# 分离文本和标签
texts, labels = zip(*ds_comments)

# 构建词典并将文本转换为向量
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(texts)
y = labels

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 定义模型
model = MultinomialNB()

# 训练模型
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 评估模型
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1-score: {f1}")
